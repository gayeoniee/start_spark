{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9207806-2987-4aef-b24d-e99242616af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "conf = SparkConf().setMaster(\"local\").setAppName(\"spark_sql_basic2\")\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba47866e-05b5-4e1a-9d34-bb227fb8f941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RDD만을 이용한 데이터 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f6890a4-0947-450c-9f99-36dcfcf0286d",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_rdd = sc.parallelize([\n",
    "    (1, (\"어벤져스\", \"마블\")),\n",
    "    (2, (\"슈퍼맨\", \"DC\")),\n",
    "    (3, (\"배트맨\", \"DC\")),\n",
    "    (4, (\"겨울왕국\", \"디즈니\")),\n",
    "    (5, (\"아이언맨\", \"마블\"))\n",
    "])\n",
    "\n",
    "attendances_rdd = sc.parallelize([\n",
    "    (1, (13934592, \"KR\")),   # 관객수\n",
    "    (2, (2182227,\"KR\")),\n",
    "    (3, (4226242, \"KR\")),\n",
    "    (4, (10303058, \"KR\")),\n",
    "    (5, (4300365, \"KR\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4acc7c55-4fe4-410e-beb6-92eb77ccf28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마블 영화 중 관객 수가 500만 이상인 영화를 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5847f49d-6255-4896-9654-a4c14a7356b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, (('슈퍼맨', 'DC'), (2182227, 'KR'))),\n",
       " (4, (('겨울왕국', '디즈니'), (10303058, 'KR'))),\n",
       " (1, (('어벤져스', '마블'), (13934592, 'KR')))]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CASE1. join 먼저, filter 나중에\n",
    "movie_att = movies_rdd.join(attendances_rdd)\n",
    "movie_att.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "138e93d9-b1a7-491b-9518-4f4d307bcac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, (('어벤져스', '마블'), (13934592, 'KR')))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_att.filter(\n",
    "    lambda x : x[1][0][1] == \"마블\" and x[1][1][0] > 5000000\n",
    ").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3074c54f-dc1f-43e0-b11c-30afe9f0fe99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, (('어벤져스', '마블'), (13934592, 'KR')))]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CASE 2. filter 먼저, join 나중에\n",
    "filtered_movies = movies_rdd.filter(lambda x : x[1][1] == '마블')\n",
    "filtered_att = attendances_rdd.filter(lambda x : x[1][0] > 5000000)\n",
    "\n",
    "filtered_movies.join(filtered_att).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adfa3358-dee6-47c8-892a-19afb73e6d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb918e5-cda7-40e4-91ca-b8b84a5499f5",
   "metadata": {},
   "source": [
    "# 데이터 프레임 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8b5759-a73f-49d8-932a-564787907f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"spark-sql\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fed3c0-af67-45eb-a276-1b5c2616bcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬럼 추가\n",
    "movies = [\n",
    "    (1, \"어벤져스\", \"마블\", 2012, 4, 26),\n",
    "    (2, \"슈퍼맨\", \"DC\", 2013, 6, 13),\n",
    "    (3, \"배트맨\", \"DC\", 2008, 8, 6),\n",
    "    (4, \"겨울왕국\", \"디즈니\", 2014, 1, 16),\n",
    "    (5, \"아이언맨\", \"마블\", 2008, 4, 30)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b9f5f3-afae-4eda-b597-287becb4d106",
   "metadata": {},
   "outputs": [],
   "source": [
    "#스키마를 알아야 한다.\n",
    "movie_schema = [\"id\", \"name\", \"company\", \"year\", \"month\", \"day\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9f53037-03f4-473e-93af-b41f38b5392a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data=movies, schema=movie_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "324b3411-9695-422b-94db-8f759b859dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', 'bigint'),\n",
       " ('name', 'string'),\n",
       " ('company', 'string'),\n",
       " ('year', 'bigint'),\n",
       " ('month', 'bigint'),\n",
       " ('day', 'bigint')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed73fc46-0812-4a18-bc7c-7e6b7acadfd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-------+----+-----+---+\n",
      "| id|    name|company|year|month|day|\n",
      "+---+--------+-------+----+-----+---+\n",
      "|  1|어벤져스|   마블|2012|    4| 26|\n",
      "|  2|  슈퍼맨|     DC|2013|    6| 13|\n",
      "|  3|  배트맨|     DC|2008|    8|  6|\n",
      "|  4|겨울왕국| 디즈니|2014|    1| 16|\n",
      "|  5|아이언맨|   마블|2008|    4| 30|\n",
      "+---+--------+-------+----+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88ad7a7f-e967-42eb-b020-55dd125edd8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|    name|\n",
      "+--------+\n",
      "|어벤져스|\n",
      "|  슈퍼맨|\n",
      "|  배트맨|\n",
      "|겨울왕국|\n",
      "|아이언맨|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"name\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "627bd28c-469f-4d6e-8bf9-5b1d313ed414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-------+----+-----+---+\n",
      "| id|    name|company|year|month|day|\n",
      "+---+--------+-------+----+-----+---+\n",
      "|  1|어벤져스|   마블|2012|    4| 26|\n",
      "|  2|  슈퍼맨|     DC|2013|    6| 13|\n",
      "|  4|겨울왕국| 디즈니|2014|    1| 16|\n",
      "+---+--------+-------+----+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.year >= 2010).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6a9dee3-4fb0-4718-9273-d81f5f31bbae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+\n",
      "|year|month|day|\n",
      "+----+-----+---+\n",
      "|2012|    4| 26|\n",
      "|2013|    6| 13|\n",
      "|2008|    8|  6|\n",
      "|2014|    1| 16|\n",
      "|2008|    4| 30|\n",
      "+----+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 년월일\n",
    "df.select(['year', 'month', 'day']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d09d3ff-7fc5-46ef-a6cc-72decf48f81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|    name|\n",
      "+--------+\n",
      "|겨울왕국|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2013년 이후 영화\n",
    "df.select('name').filter(df.year > 2013).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95372693-4b35-407a-acee-70ad46f234de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+\n",
      "|    name|company|\n",
      "+--------+-------+\n",
      "|어벤져스|   마블|\n",
      "|  슈퍼맨|     DC|\n",
      "|  배트맨|     DC|\n",
      "|아이언맨|   마블|\n",
      "+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 마블영화, DC 같이 꺼내기\n",
    "df.select(['name', 'company']).filter((df.company == '마블') | (df.company == 'DC')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7a14c29-62e0-4f5d-b913-0e1437645aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222e80e2-fe2f-4740-8169-2c1a4cc74dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b90571e-db08-476b-957f-653dff06e3b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6f5a86-505c-402a-9bb0-ba03a30f8c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d65f66be-dbb3-4689-b717-a42924cf56f5",
   "metadata": {},
   "source": [
    "# Spark SQL 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b95cda8c-5284-4d3f-acfd-5dcd3587b8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"spark-sql\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b2e3bb6-a8b1-4406-9058-4ec580374526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬럼 추가\n",
    "movies = [\n",
    "    (1, \"어벤져스\", \"마블\", 2012, 4, 26),\n",
    "    (2, \"슈퍼맨\", \"DC\", 2013, 6, 13),\n",
    "    (3, \"배트맨\", \"DC\", 2008, 8, 6),\n",
    "    (4, \"겨울왕국\", \"디즈니\", 2014, 1, 16),\n",
    "    (5, \"아이언맨\", \"마블\", 2008, 4, 30)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba82f273-ee51-4a3b-8da8-d826752ddc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#스키마를 알아야 한다.\n",
    "movie_schema = [\"id\", \"name\", \"company\", \"year\", \"month\", \"day\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a51d754-336c-4900-948a-1b4ee3e5c8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data=movies, schema=movie_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78360356-7075-4641-8af5-3a31c4dd1ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"movies\")  # 뷰의 이름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c49d91b2-4442-4fc2-8493-22efa1dc7c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|    name|\n",
      "+--------+\n",
      "|어벤져스|\n",
      "|  슈퍼맨|\n",
      "|  배트맨|\n",
      "|겨울왕국|\n",
      "|아이언맨|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 영화 이름만 가져오기\n",
    "\n",
    "query = \"\"\"\n",
    "\n",
    "SELECT name\n",
    "  FROM movies\n",
    "\n",
    "\"\"\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84e3c76d-be9c-4f13-8398-79d125dbf87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|    name|\n",
      "+--------+\n",
      "|어벤져스|\n",
      "|  슈퍼맨|\n",
      "|겨울왕국|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2010년 이후에 개봉한 영화를 조회\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT name\n",
    "    FROM movies\n",
    "    WHERE year > 2010\n",
    "\"\"\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3588921-0519-42e7-91df-6cbb55dc0259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+\n",
      "|    name|company|\n",
      "+--------+-------+\n",
      "|  배트맨|     DC|\n",
      "|아이언맨|   마블|\n",
      "+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2012년도 이전에 개봉한 영화의 이름과 회사를 출력\n",
    "query = \"\"\"\n",
    "    SELECT name, company\n",
    "    FROM movies\n",
    "    WHERE year < 2012\n",
    "\"\"\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "673549e2-13cd-4dbf-8fb5-e68b6e9bd795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-------+----+-----+---+\n",
      "| id|    name|company|year|month|day|\n",
      "+---+--------+-------+----+-----+---+\n",
      "|  2|  슈퍼맨|     DC|2013|    6| 13|\n",
      "|  3|  배트맨|     DC|2008|    8|  6|\n",
      "|  5|아이언맨|   마블|2008|    4| 30|\n",
      "+---+--------+-------+----+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# like 문자열 데이터에서 특정 단어나 문장을 포함한 데이터를 찾을 때\n",
    "# % 기호를 사용해서 문장이 매칭되는지 확인 가능!\n",
    "# 제목이 ~~맨으로 끝나는 데이터의 모든 정보를 조회\n",
    "query = \"\"\"\n",
    "    SELECT * \n",
    "    FROM movies\n",
    "    WHERE name LIKE '%맨'\n",
    "\"\"\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e240a1b-c063-4752-b842-19429043a4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-------+----+-----+---+\n",
      "| id|    name|company|year|month|day|\n",
      "+---+--------+-------+----+-----+---+\n",
      "|  1|어벤져스|   마블|2012|    4| 26|\n",
      "|  2|  슈퍼맨|     DC|2013|    6| 13|\n",
      "|  3|  배트맨|     DC|2008|    8|  6|\n",
      "|  5|아이언맨|   마블|2008|    4| 30|\n",
      "+---+--------+-------+----+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# BETWEEN 특정 데이터와 데이터 사이를 조회\n",
    "# 개봉 월이 4 ~ 8월 사이. 4 <= 개봉월 <= 8\n",
    "query = \"\"\"\n",
    "    SELECT * \n",
    "    FROM movies\n",
    "    WHERE month BETWEEN 4 AND 8\n",
    "\"\"\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cb119c-6661-4638-88f0-aa5e9f031659",
   "metadata": {},
   "source": [
    "# join 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fed590c5-2cdc-4cfa-8c9e-d2160e0d132c",
   "metadata": {},
   "outputs": [],
   "source": [
    "attendances = [\n",
    "    (1, 13934592., \"KR\"),\n",
    "    (2, 2182227.,\"KR\"),\n",
    "    (3, 4226242., \"KR\"),\n",
    "    (4, 10303058., \"KR\"),\n",
    "    (5, 4300365., \"KR\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5374f569-8410-4b70-b833-1734b53dae41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 직접 스키마 지정해 보기\n",
    "from pyspark.sql.types import StringType, FloatType\\\n",
    "    , IntegerType\\\n",
    "    , StructType, StructField"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f45c8ebe-15d7-4a8d-9e3d-3494f5d2e682",
   "metadata": {},
   "outputs": [],
   "source": [
    "att_schema = StructType([ # 모든 컬럼의 타입을 통칭 - 컬럼 데이터의 집합\n",
    "    StructField(\"id\", IntegerType(), True), # StructField : 컬럼\n",
    "    StructField(\"att\", FloatType(), True),\n",
    "    StructField(\"theater_country\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eddbecb9-24eb-497f-9978-87098786d005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', 'int'), ('att', 'float'), ('theater_country', 'string')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_df = spark.createDataFrame(\n",
    "    data=attendances,\n",
    "    schema=att_schema\n",
    ")\n",
    "\n",
    "att_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "37678b37-8a67-4e61-8173-745058041a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "att_df.createOrReplaceTempView(\"att\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "badc2ac7-6c31-49e6-9dd7-79d465a36548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+---------------+\n",
      "| id|        att|theater_country|\n",
      "+---+-----------+---------------+\n",
      "|  1|1.3934592E7|             KR|\n",
      "|  2|  2182227.0|             KR|\n",
      "|  3|  4226242.0|             KR|\n",
      "|  4|1.0303058E7|             KR|\n",
      "|  5|  4300365.0|             KR|\n",
      "+---+-----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "att_df.select('*').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e9ffea8a-b3cf-463c-89f0-41261c416b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-------+-----------+\n",
      "| id|    name|company|        att|\n",
      "+---+--------+-------+-----------+\n",
      "|  1|어벤져스|   마블|1.3934592E7|\n",
      "|  2|  슈퍼맨|     DC|  2182227.0|\n",
      "|  3|  배트맨|     DC|  4226242.0|\n",
      "|  4|겨울왕국| 디즈니|1.0303058E7|\n",
      "|  5|아이언맨|   마블|  4300365.0|\n",
      "+---+--------+-------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df와 join\n",
    "query = '''\n",
    "    select movies.id, movies.name, movies.company, att.att\n",
    "    from movies\n",
    "    join att on movies.id = att.id\n",
    "'''\n",
    "\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f9b883b4-e97b-43de-a473-de34033e50e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db0f4f2-5b32-4262-9ab2-7aab904e7dda",
   "metadata": {},
   "source": [
    "# SQL 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b8851466-868b-44d2-99d9-7d800fc25dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"trip_count_sql\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b5cf82df-bc54-4435-90a2-3b2952f7d10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_file = \"learning_spark_data/fhvhv_tripdata_2020-03.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c75fcd41-c5e9-4784-b210-0ad5c96c1748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inferSchema : 자동으로 스키마 예측하게 하기\n",
    "data = spark.read.csv(trip_file, inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cfb16ec4-a076-4491-a767-48e798d3c357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13392904"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a04996dc-7fb0-4cbb-bb36-0bbe65edc03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.createOrReplaceTempView(\"mobility_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d366caeb-ff84-41b5-8fda-cce061f25685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "|hvfhs_license_num|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|SR_Flag|\n",
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "|           HV0005|              B02510|2020-03-01 00:03:40|2020-03-01 00:23:39|          81|         159|   NULL|\n",
      "|           HV0005|              B02510|2020-03-01 00:28:05|2020-03-01 00:38:57|         168|         119|   NULL|\n",
      "|           HV0003|              B02764|2020-03-01 00:03:07|2020-03-01 00:15:04|         137|         209|      1|\n",
      "|           HV0003|              B02764|2020-03-01 00:18:42|2020-03-01 00:38:42|         209|          80|   NULL|\n",
      "|           HV0003|              B02764|2020-03-01 00:44:24|2020-03-01 00:58:44|         256|         226|   NULL|\n",
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = '''\n",
    "    select *\n",
    "    from mobility_data\n",
    "    limit 5\n",
    "'''\n",
    "\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1924e7c-c026-4665-903e-1f80adc287d5",
   "metadata": {},
   "source": [
    "## 스파크 SQL을 사용하는 이유"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d5ec613e-5872-4d9f-a664-b959bf481f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+\n",
      "|pickup_date| trips|\n",
      "+-----------+------+\n",
      "| 2020-03-03|697880|\n",
      "| 2020-03-02|648986|\n",
      "| 2020-03-01|784246|\n",
      "| 2020-03-06|872012|\n",
      "| 2020-03-05|731165|\n",
      "| 2020-03-04|707879|\n",
      "| 2020-03-09|628940|\n",
      "| 2020-03-08|731222|\n",
      "| 2020-03-07|886071|\n",
      "| 2020-03-10|626474|\n",
      "| 2020-03-12|643257|\n",
      "| 2020-03-11|628601|\n",
      "| 2020-03-16|391518|\n",
      "| 2020-03-13|660914|\n",
      "| 2020-03-15|448125|\n",
      "| 2020-03-14|569397|\n",
      "| 2020-03-26|141607|\n",
      "| 2020-03-25|141088|\n",
      "| 2020-03-20|261900|\n",
      "| 2020-03-24|141686|\n",
      "+-----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "select split(pickup_datetime, ' ')[0] as pickup_date, count(*) as trips\n",
    "from mobility_data\n",
    "group by pickup_date\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c4c6f1eb-abe0-4fe4-8932-0b49e9749434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Aggregate ['pickup_date], ['split('pickup_datetime,  )[0] AS pickup_date#382, 'count(1) AS trips#383]\n",
      "+- 'UnresolvedRelation [mobility_data], [], false\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "pickup_date: string, trips: bigint\n",
      "Aggregate [split(cast(pickup_datetime#266 as string),  , -1)[0]], [split(cast(pickup_datetime#266 as string),  , -1)[0] AS pickup_date#382, count(1) AS trips#383L]\n",
      "+- SubqueryAlias mobility_data\n",
      "   +- View (`mobility_data`, [hvfhs_license_num#264,dispatching_base_num#265,pickup_datetime#266,dropoff_datetime#267,PULocationID#268,DOLocationID#269,SR_Flag#270])\n",
      "      +- Relation [hvfhs_license_num#264,dispatching_base_num#265,pickup_datetime#266,dropoff_datetime#267,PULocationID#268,DOLocationID#269,SR_Flag#270] csv\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Aggregate [_groupingexpression#387], [_groupingexpression#387 AS pickup_date#382, count(1) AS trips#383L]\n",
      "+- Project [split(cast(pickup_datetime#266 as string),  , -1)[0] AS _groupingexpression#387]\n",
      "   +- Relation [hvfhs_license_num#264,dispatching_base_num#265,pickup_datetime#266,dropoff_datetime#267,PULocationID#268,DOLocationID#269,SR_Flag#270] csv\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- HashAggregate(keys=[_groupingexpression#387], functions=[count(1)], output=[pickup_date#382, trips#383L])\n",
      "   +- Exchange hashpartitioning(_groupingexpression#387, 200), ENSURE_REQUIREMENTS, [plan_id=457]\n",
      "      +- HashAggregate(keys=[_groupingexpression#387], functions=[partial_count(1)], output=[_groupingexpression#387, count#389L])\n",
      "         +- Project [split(cast(pickup_datetime#266 as string),  , -1)[0] AS _groupingexpression#387]\n",
      "            +- FileScan csv [pickup_datetime#266] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/home/jovyan/work/learning_spark_data/fhvhv_tripdata_2020-03.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<pickup_datetime:timestamp>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 실행 계획 살펴보기\n",
    "spark.sql(query).explain(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "76510ca4-0539-4544-97c2-70203c996408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Aggregate ['pickup_date], ['pickup_date, 'count(1) AS trips#391]\n",
      "+- 'SubqueryAlias __auto_generated_subquery_name\n",
      "   +- 'Project ['split('pickup_datetime,  )[0] AS pickup_date#390]\n",
      "      +- 'UnresolvedRelation [mobility_data], [], false\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "pickup_date: string, trips: bigint\n",
      "Aggregate [pickup_date#390], [pickup_date#390, count(1) AS trips#391L]\n",
      "+- SubqueryAlias __auto_generated_subquery_name\n",
      "   +- Project [split(cast(pickup_datetime#266 as string),  , -1)[0] AS pickup_date#390]\n",
      "      +- SubqueryAlias mobility_data\n",
      "         +- View (`mobility_data`, [hvfhs_license_num#264,dispatching_base_num#265,pickup_datetime#266,dropoff_datetime#267,PULocationID#268,DOLocationID#269,SR_Flag#270])\n",
      "            +- Relation [hvfhs_license_num#264,dispatching_base_num#265,pickup_datetime#266,dropoff_datetime#267,PULocationID#268,DOLocationID#269,SR_Flag#270] csv\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Aggregate [pickup_date#390], [pickup_date#390, count(1) AS trips#391L]\n",
      "+- Project [split(cast(pickup_datetime#266 as string),  , -1)[0] AS pickup_date#390]\n",
      "   +- Relation [hvfhs_license_num#264,dispatching_base_num#265,pickup_datetime#266,dropoff_datetime#267,PULocationID#268,DOLocationID#269,SR_Flag#270] csv\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- HashAggregate(keys=[pickup_date#390], functions=[count(1)], output=[pickup_date#390, trips#391L])\n",
      "   +- Exchange hashpartitioning(pickup_date#390, 200), ENSURE_REQUIREMENTS, [plan_id=472]\n",
      "      +- HashAggregate(keys=[pickup_date#390], functions=[partial_count(1)], output=[pickup_date#390, count#396L])\n",
      "         +- Project [split(cast(pickup_datetime#266 as string),  , -1)[0] AS pickup_date#390]\n",
      "            +- FileScan csv [pickup_datetime#266] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/home/jovyan/work/learning_spark_data/fhvhv_tripdata_2020-03.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<pickup_datetime:timestamp>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 두번째 쿼리\n",
    "spark.sql(\"\"\"select \n",
    "                pickup_date, \n",
    "                count(*) as trips\n",
    "             from ( select\n",
    "                          split(pickup_datetime, ' ')[0] as pickup_date\n",
    "                          from mobility_data )\n",
    "             group by pickup_date\"\"\").explain(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6075c6-3ff6-48b2-af03-62440c5ffe40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786ec4b0-b28e-429e-94f6-192885d3a030",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7db8b870-4bfd-47fc-89e8-07187b8a991f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d7ec2f-0db1-43f1-a17e-c72b7a0ea764",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cc5df3d6-074a-48f6-8747-709596d06ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 운행 데이터 프레임 생성, Zone 데이터프레임 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440d5940-9c80-472b-8c34-2a79175665e7",
   "metadata": {},
   "source": [
    "trip_file = \"fhvhv_tripdata_2020-03.csv\"   \n",
    "zone_file = \"taxi+_zone_lookup.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "240018f2-db6b-4014-8d88-85c68b4327b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"trip_count_sql\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "389ed8b0-a341-453a-9c29-639ccdb5019c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_data = spark.read.format('csv')\\\n",
    "        .option('header','true')\\\n",
    "        .option('inferSchema', 'true')\\\n",
    "        .load(\"learning_spark_data/fhvhv_tripdata_2020-03.csv\")      \n",
    "\n",
    "zone_data = spark.read.format('csv')\\\n",
    "        .option('header','true')\\\n",
    "        .option('inferSchema', 'true')\\\n",
    "        .load(\"learning_spark_data/taxi+_zone_lookup.csv\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a4db4fc4-d9fb-4dcc-ace5-3643b04ac7d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- hvfhs_license_num: string (nullable = true)\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- SR_Flag: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trip_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f22d734c-78ba-4507-8d33-5227948a595e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- LocationID: integer (nullable = true)\n",
      " |-- Borough: string (nullable = true)\n",
      " |-- Zone: string (nullable = true)\n",
      " |-- service_zone: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zone_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "821b4d61-86c4-4299-88af-0646166d4425",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_data.createOrReplaceTempView(\"trips\")\n",
    "zone_data.createOrReplaceTempView(\"zones\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5da8dc6d-a52b-4508-b80a-b152850b9585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+\n",
      "|PULocationID|count(1)|\n",
      "+------------+--------+\n",
      "|         148|  116205|\n",
      "|         243|   87431|\n",
      "|          31|    5285|\n",
      "|         137|   85552|\n",
      "|          85|   46120|\n",
      "+------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 승차 Location(PULocationID)별 개수 세기\n",
    "query = '''\n",
    "    SELECT PULocationID, COUNT(*)\n",
    "    FROM trips\n",
    "    GROUP BY PULocationID\n",
    "'''\n",
    "\n",
    "spark.sql(query).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bcd1fe98-7831-4f24-a123-878c035fe9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+\n",
      "|DOLocationID|count(1)|\n",
      "+------------+--------+\n",
      "|         148|   91601|\n",
      "|         243|   86795|\n",
      "|          31|    5526|\n",
      "|          85|   44509|\n",
      "|         137|   80098|\n",
      "+------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 하차 Location(DOLocationID)별 개수 세기\n",
    "query = '''\n",
    "    SELECT DOLocationID, COUNT(*)\n",
    "    FROM trips\n",
    "    GROUP BY DOLocationID\n",
    "'''\n",
    "\n",
    "spark.sql(query).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d8663771-efed-4774-be0f-1e1eacf5e6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+--------+\n",
      "|PULocationID|                Zone|count(1)|\n",
      "+------------+--------------------+--------+\n",
      "|         181|          Park Slope|   79235|\n",
      "|         182|         Parkchester|   33478|\n",
      "|         166| Morningside Heights|   46653|\n",
      "|         250|Westchester Villa...|   30788|\n",
      "|          18|        Bedford Park|   70536|\n",
      "+------------+--------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# HV0003 운송사업자의 승차 지역별 트립 건수를 집계하고, \n",
    "query = '''\n",
    "    SELECT trips.PULocationID, zones.Zone, COUNT(*)\n",
    "    FROM trips\n",
    "    JOIN zones\n",
    "    ON trips.PULocationID = zones.LocationID\n",
    "    WHERE hvfhs_license_num = 'HV0003'\n",
    "    GROUP BY trips.PULocationID, zones.Zone\n",
    "'''\n",
    "\n",
    "spark.sql(query).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "122e4895-0597-4c9a-aa35-14711f6febd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------+\n",
      "|hvfhs_license_num|count(1)|\n",
      "+-----------------+--------+\n",
      "|           HV0003| 9836763|\n",
      "|           HV0005| 3219535|\n",
      "|           HV0004|  336606|\n",
      "+-----------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 가장 많은 운송사업자순으로 정렬하는 분석 쿼리  hvfhs_license_num\n",
    "query = '''\n",
    "    SELECT hvfhs_license_num,COUNT(*)\n",
    "    FROM trips\n",
    "    GROUP BY hvfhs_license_num\n",
    "    ORDER BY COUNT(*) DESC\n",
    "'''\n",
    "\n",
    "spark.sql(query).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2066c6e2-cf51-44ba-a699-60f2253ebe51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------+\n",
      "|hvfhs_license_num|count(1)|\n",
      "+-----------------+--------+\n",
      "|           HV0004|  336606|\n",
      "|           HV0005| 3219535|\n",
      "|           HV0003| 9836763|\n",
      "+-----------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 운송사별 운행 건수 비교\n",
    "query = '''\n",
    "    SELECT hvfhs_license_num, COUNT(*)\n",
    "    FROM trips\n",
    "    GROUP BY hvfhs_license_num\n",
    "'''\n",
    "\n",
    "spark.sql(query).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "91640325-a313-4f83-a619-54ee98fa79e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+\n",
      "|      Borough|count(1)|\n",
      "+-------------+--------+\n",
      "|    Manhattan| 4953140|\n",
      "|     Brooklyn| 3735764|\n",
      "|       Queens| 2437383|\n",
      "|        Bronx| 2086592|\n",
      "|Staten Island|  178818|\n",
      "+-------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 승차 위치 Borough별 운행 건수\n",
    "query = '''\n",
    "    SELECT  zones.Borough, COUNT(*)\n",
    "    FROM trips\n",
    "    JOIN zones\n",
    "    ON trips.PULocationID = zones.LocationID\n",
    "    GROUP BY zones.Borough\n",
    "    ORDER BY COUNT(*) DESC\n",
    "'''\n",
    "\n",
    "spark.sql(query).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83316752-7a99-4f25-a486-f27d8b21c397",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6173033b-036c-43a5-9b64-d33a10af2a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+----------+\n",
      "|service_zone|total_pickup|total_drop|\n",
      "+------------+------------+----------+\n",
      "|    Airports|      319610|    411156|\n",
      "|   Boro Zone|     9046897|   8885136|\n",
      "|         EWR|         362|     65066|\n",
      "|         N/A|         845|    387759|\n",
      "| Yellow Zone|     4025190|   3643787|\n",
      "+------------+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#서비스 존별 승차/하차 건수\n",
    "from pyspark.sql.functions import sum\n",
    "\n",
    "pickup_df = trip_data.groupBy(\"PULocationID\").count().withColumnRenamed(\"count\", \"pickup_count\")\n",
    "drop_df = trip_data.groupBy(\"DOLocationID\").count().withColumnRenamed(\"count\", \"drop_count\")\n",
    "\n",
    "pickup_joined = pickup_df.join(\n",
    "    zone_data,\n",
    "    pickup_df.PULocationID == zone_data.LocationID,\n",
    "    how=\"left\"\n",
    ").groupBy(\"service_zone\").agg(sum(\"pickup_count\").alias(\"total_pickup\"))\n",
    "\n",
    "drop_joined = drop_df.join(\n",
    "    zone_data,\n",
    "    drop_df.DOLocationID == zone_data.LocationID,\n",
    "    how=\"left\"\n",
    ").groupBy(\"service_zone\").agg(sum(\"drop_count\").alias(\"total_drop\"))\n",
    "\n",
    "result_df = pickup_joined.join(\n",
    "    drop_joined,\n",
    "    on=\"service_zone\",\n",
    "    how=\"outer\"\n",
    ")\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e63d228-db4f-4f98-ba4b-11edcdc589c9",
   "metadata": {},
   "source": [
    "## 혼자 생각해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "eca312e6-90f5-4561-b4c1-f956015a9de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+\n",
      "|  weekday|trip_count|\n",
      "+---------+----------+\n",
      "|   Sunday|   2241151|\n",
      "|   Monday|   1964429|\n",
      "|   Friday|   1954165|\n",
      "|  Tuesday|   1907888|\n",
      "| Saturday|   1809669|\n",
      "| Thursday|   1768802|\n",
      "|Wednesday|   1746800|\n",
      "+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. 요일별 승차 건수 분석\n",
    "from pyspark.sql.functions import date_format, count\n",
    "\n",
    "trip_weekday = trip_data.withColumn('weekday', date_format('pickup_datetime', 'EEEE'))\n",
    "\n",
    "weekday_counts = trip_weekday.groupBy('weekday')\\\n",
    "    .agg(count('*').alias('trip_count'))\\\n",
    "    .orderBy('trip_count', ascending=False)\n",
    "\n",
    "weekday_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "76431b6e-3f97-43e2-acc6-cdc4da3e9440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+----------+\n",
      "|service_zone|  weekday|trip_count|\n",
      "+------------+---------+----------+\n",
      "|   Boro Zone|   Sunday|   1528460|\n",
      "|   Boro Zone|   Friday|   1333359|\n",
      "|   Boro Zone|   Monday|   1326991|\n",
      "|   Boro Zone|  Tuesday|   1274010|\n",
      "|   Boro Zone| Saturday|   1265210|\n",
      "|   Boro Zone| Thursday|   1170749|\n",
      "|   Boro Zone|Wednesday|   1148118|\n",
      "| Yellow Zone|   Sunday|    646283|\n",
      "| Yellow Zone|  Tuesday|    588357|\n",
      "| Yellow Zone|   Friday|    583137|\n",
      "+------------+---------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Zone + 요일 조합별 승차 건수 분석\n",
    "pickup_joined = trip_weekday.join(\n",
    "    zone_data,\n",
    "    trip_weekday.PULocationID == zone_data.LocationID,\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "zone_weekday_counts = pickup_joined.groupBy('service_zone', 'weekday')\\\n",
    "    .agg(count(\"*\").alias('trip_count'))\\\n",
    "    .orderBy('trip_count', ascending=False)\n",
    "\n",
    "zone_weekday_counts.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cfe80948-455c-4f8d-b8ef-e7b3c36d2846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+----------+----+\n",
      "|service_zone|  weekday|trip_count|rank|\n",
      "+------------+---------+----------+----+\n",
      "|   Boro Zone|   Friday|   1333359|   1|\n",
      "|   Boro Zone|   Monday|   1326991|   1|\n",
      "|   Boro Zone| Saturday|   1265210|   1|\n",
      "|   Boro Zone|   Sunday|   1528460|   1|\n",
      "|   Boro Zone| Thursday|   1170749|   1|\n",
      "|   Boro Zone|  Tuesday|   1274010|   1|\n",
      "|   Boro Zone|Wednesday|   1148118|   1|\n",
      "+------------+---------+----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. 요일별 가장 붐비는 서비스 존\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "\n",
    "window_spec = Window.partitionBy('weekday').orderBy(zone_weekday_counts['trip_count'].desc())\n",
    "ranked_zone_by_weekday = zone_weekday_counts.withColumn('rank', row_number().over(window_spec))\n",
    "\n",
    "top_zone_each_weekday = ranked_zone_by_weekday.filter(\"rank == 1\").orderBy('weekday')\n",
    "top_zone_each_weekday.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1bdabc-96b2-4bcd-8341-1ecc28c275ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

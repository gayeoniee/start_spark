{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e06c309-dd46-4bd7-ac98-2ee95917c4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "MAX_MEMORY = '8g'\n",
    "spark = SparkSession.builder.appName('taxi-fare-prediction_2nd')\\\n",
    "                    .config('spark.driver.memory', MAX_MEMORY)\\\n",
    "                    .config('spark.executor.memory', MAX_MEMORY)\\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "164fbe9e-b400-48fe-bb4f-66f65b407df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "trip_data_path = os.path.join(cwd, 'learning_spark_data', 'trips', '*.csv')\n",
    "file_path = f\"file:///{trip_data_path.replace(os.sep, '/')}\"\n",
    "trip_df = spark.read.csv(file_path, inferSchema=True, header=True)\n",
    "trip_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39d11a14-e4a2-46aa-8798-7d37597caa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_df.createOrReplaceTempView('trips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f8602f9-9d12-4c6f-81f0-4cbf9dbb71fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "    SELECT \n",
    "        passenger_count,\n",
    "        PULocationID as pickup_location_id,\n",
    "        DOLocationID as dropoff_location_id,\n",
    "        trip_distance,\n",
    "        HOUR(tpep_pickup_datetime) as pickup_time,\n",
    "        DATE_FORMAT(TO_DATE(tpep_pickup_datetime), 'EEEE') AS day_of_week,\n",
    "        total_amount\n",
    "    FROM\n",
    "        trips\n",
    "    WHERE\n",
    "        total_amount < 5000\n",
    "        AND total_amount > 0\n",
    "        AND trip_distance > 0\n",
    "        AND trip_distance < 500\n",
    "        AND passenger_count < 4\n",
    "        AND TO_DATE(tpep_pickup_datetime) >= '2021-01-01'\n",
    "        AND TO_DATE(tpep_pickup_datetime) < '2021-08-01'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c25d0be-658a-44d0-8ed0-ce771c364cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = spark.sql(query)\n",
    "data_df.createOrReplaceTempView('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "24db7823-ad10-4e3a-a3bb-b66f65937772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------------+-------------------+-------------+-----------+-----------+------------+\n",
      "|passenger_count|pickup_location_id|dropoff_location_id|trip_distance|pickup_time|day_of_week|total_amount|\n",
      "+---------------+------------------+-------------------+-------------+-----------+-----------+------------+\n",
      "|              0|               138|                265|         16.5|          0|     Monday|       70.07|\n",
      "|              1|                68|                264|         1.13|          0|     Monday|       11.16|\n",
      "|              1|               239|                262|         2.68|          0|     Monday|       18.59|\n",
      "|              1|               186|                 91|         12.4|          0|     Monday|        43.8|\n",
      "|              2|               132|                265|          9.7|          0|     Monday|        32.3|\n",
      "+---------------+------------------+-------------------+-------------+-----------+-----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select * from data limit 5').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be9c6b88-d7a9-4578-897f-9754bc6be18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = data_df.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89374647-6998-4e5e-a3cb-bdc2e9f7e598",
   "metadata": {},
   "source": [
    "# 파이프라인 생성\n",
    "- 전처리 과정을 각 스테이지로 정의해서 쌓아줌\n",
    "- [범주형] StringIndexer + onehotencoding > 'pickup_location_id', 'dropoff_location_id', 'day_of_week'\n",
    "- [수치형] Vectorassembler, StandardScaler > 'passenger_count', 'trip_distance', 'pickup_time'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "42b60c9b-62e5-4d33-98ea-b0b7a2749b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, OneHotEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5f6678aa-fd5c-4757-898b-e7d0383fc4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2fcb8fc9-a7c1-4d1c-8e2b-2ba78f72253c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_6e318c54a75f,\n",
       " OneHotEncoder_a8819829b0e0,\n",
       " StringIndexer_b372654022cd,\n",
       " OneHotEncoder_42124236f939,\n",
       " StringIndexer_e16732074e59,\n",
       " OneHotEncoder_fb61272d411c]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features = ['pickup_location_id', 'dropoff_location_id', 'day_of_week']\n",
    "\n",
    "for cat in cat_features:\n",
    "    cat_index = StringIndexer(inputCol=cat, outputCol=cat+'_idx').setHandleInvalid('keep')\n",
    "    onehot_encode = OneHotEncoder(inputCols=[cat_index.getOutputCol()], outputCols=[cat+'_onehot'])\n",
    "    stages += [cat_index, onehot_encode]  # col list\n",
    "stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0eea9cd6-909c-45ea-b9be-f346d195a144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_6e318c54a75f,\n",
       " OneHotEncoder_a8819829b0e0,\n",
       " StringIndexer_b372654022cd,\n",
       " OneHotEncoder_42124236f939,\n",
       " StringIndexer_e16732074e59,\n",
       " OneHotEncoder_fb61272d411c,\n",
       " VectorAssembler_0fc409cf09ce,\n",
       " StandardScaler_552ff29606ac,\n",
       " VectorAssembler_eb142e822879,\n",
       " StandardScaler_ea56b1aec20c,\n",
       " VectorAssembler_3e90929562ae,\n",
       " StandardScaler_0d563182b800]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorassembler\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "num_features = ['passenger_count', 'trip_distance', 'pickup_time']\n",
    "\n",
    "for num in num_features:\n",
    "    num_assembler = VectorAssembler(\n",
    "        inputCols=[num],\n",
    "        outputCol=num+'_vector'\n",
    "    )\n",
    "    num_scaler = StandardScaler(inputCol=num_assembler.getOutputCol(), outputCol=num+'_scaled')\n",
    "    stages += [num_assembler, num_scaler]\n",
    "stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "61cef16e-f4ed-4541-bd94-962cf3d98b27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pickup_location_id_onehot',\n",
       " 'dropoff_location_id_onehot',\n",
       " 'day_of_week_onehot',\n",
       " 'passenger_count_scaled',\n",
       " 'trip_distance_scaled',\n",
       " 'pickup_time_scaled']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assembler_input = [cat+'_onehot' for cat in cat_features] + [num+'_scaled' for num in num_features]\n",
    "assembler_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "178cf490-bed6-4455-bbc6-405885cc03e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_6e318c54a75f,\n",
       " OneHotEncoder_a8819829b0e0,\n",
       " StringIndexer_b372654022cd,\n",
       " OneHotEncoder_42124236f939,\n",
       " StringIndexer_e16732074e59,\n",
       " OneHotEncoder_fb61272d411c,\n",
       " VectorAssembler_0fc409cf09ce,\n",
       " StandardScaler_552ff29606ac,\n",
       " VectorAssembler_eb142e822879,\n",
       " StandardScaler_ea56b1aec20c,\n",
       " VectorAssembler_3e90929562ae,\n",
       " StandardScaler_0d563182b800,\n",
       " VectorAssembler_805631bd348e]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assembler = VectorAssembler(inputCols=assembler_input, outputCol='feature_vector')\n",
    "stages += [assembler]\n",
    "stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a8de7d19-2f2e-48ab-957a-81ca16061291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- pickup_location_id: integer (nullable = true)\n",
      " |-- dropoff_location_id: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- pickup_time: integer (nullable = true)\n",
      " |-- day_of_week: string (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- pickup_location_id_idx: double (nullable = false)\n",
      " |-- pickup_location_id_onehot: vector (nullable = true)\n",
      " |-- dropoff_location_id_idx: double (nullable = false)\n",
      " |-- dropoff_location_id_onehot: vector (nullable = true)\n",
      " |-- day_of_week_idx: double (nullable = false)\n",
      " |-- day_of_week_onehot: vector (nullable = true)\n",
      " |-- passenger_count_vector: vector (nullable = true)\n",
      " |-- passenger_count_scaled: vector (nullable = true)\n",
      " |-- trip_distance_vector: vector (nullable = true)\n",
      " |-- trip_distance_scaled: vector (nullable = true)\n",
      " |-- pickup_time_vector: vector (nullable = true)\n",
      " |-- pickup_time_scaled: vector (nullable = true)\n",
      " |-- feature_vector: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages=stages)\n",
    "fitted_transform = pipeline.fit(train_df)\n",
    "vtrain_df = fitted_transform.transform(train_df)\n",
    "vtrain_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0f1bc5cc-0037-4b63-a38f-1c34cd3dd63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|      feature_vector|\n",
      "+--------------------+\n",
      "|(534,[62,312,528,...|\n",
      "|(534,[62,281,527,...|\n",
      "+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vtrain_df.select('feature_vector').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3f2a7ec3-2478-4493-95f1-a9236ee4ccc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "lr = LinearRegression(maxIter=50, solver='normal', labelCol='total_amount', featuresCol='feature_vector')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a6c9295c-2ccb-4eda-84d9-41cc5e5c340a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lr.fit(vtrain_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6dd0cb22-12d2-4744-9e57-c7e2056707ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트데이터도 변환\n",
    "vtest_df = fitted_transform.transform(test_df)\n",
    "# 테스트데이터로 예측\n",
    "pred = model.transform(vtest_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f8ecd349-360c-428b-9bc9-1586258a0420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[passenger_count: int, pickup_location_id: int, dropoff_location_id: int, trip_distance: double, pickup_time: int, day_of_week: string, total_amount: double, pickup_location_id_idx: double, pickup_location_id_onehot: vector, dropoff_location_id_idx: double, dropoff_location_id_onehot: vector, day_of_week_idx: double, day_of_week_onehot: vector, passenger_count_vector: vector, passenger_count_scaled: vector, trip_distance_vector: vector, trip_distance_scaled: vector, pickup_time_vector: vector, pickup_time_scaled: vector, feature_vector: vector, prediction: double]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e60b56b4-b579-4dd8-9147-590085e135b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+\n",
      "|total_amount|        prediction|\n",
      "+------------+------------------+\n",
      "|       12.35| 12.62900702706409|\n",
      "|        11.8|14.466237679610787|\n",
      "|        12.3|14.775495186138414|\n",
      "+------------+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred.select('total_amount', 'prediction').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9ae04385-48be-4c63-beaf-bf41fd9a4bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7966956145005624, 5.863545681582043)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary.r2, model.summary.rootMeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d9db3f4a-e169-435c-b6d6-f374cccf1985",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3949068-42ee-4da1-a880-78d0477a6828",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdeb4470-6adb-4e90-bd06-b89f1b2191d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
